<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python" alt="Python Version">
  <img src="https://img.shields.io/badge/PyTorch-1.9%2B-orange?style=for-the-badge&logo=pytorch" alt="PyTorch Version">
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License">
</p>

<h1 align="center">VISTA-S: Visual Inference System for Target Assessment</h1>
<h2 align="center">DualityAI Space Station Model</h2>

<p align="center">
  <b>Welcome to <strong>VISTA-S</strong></b> â€” a cutting-edge, high-precision AI system for <b>object detection</b> and visual inference.<br>
  Inspired by the mysteries of space, VISTA-S delivers powerful computer vision capabilities with ease and elegance. ğŸŒŒ
</p>

---

## âœ¨ Features

- **State-of-the-Art Detection:** Built on YOLOv8 for high-precision object detection.
- **Optimized Performance:** Fast, efficient inference for real-time applications.
- **Interactive Demo:** Visualize and interact with predictions through an easy-to-use web app.
- **Seamless Data Integration:** Streamlined data preparation and handling for a smooth workflow.

---

## ğŸ“¸ VISTA-S in Action


[![Watch the video](https://img.youtube.com/vi/gH7p3Jfavg0/maxresdefault.jpg)](https://youtu.be/gH7p3Jfavg0?si=kfichBROCP6rzNP4)

---

## âš¡ Quickstart

**Get up and running in minutes!**

### 1. Create Environment

```bash
conda env create -f environment.yaml
```

### 2. Activate Environment

```bash
conda activate VISTA
```

---

## ğŸ“‹ Dataset Usage Discipline

**This model was trained exclusively on the Falcon synthetic dataset provided for the Duality AI Space Station Challenge, with strict train/val/test separation.**

### Dataset Structure & Compliance
- **Training:** `train/` directory only - used exclusively during model training
- **Validation:** `val/` directory only - used exclusively during validation phases  
- **Testing:** `test/` directory only - used exclusively during evaluation phases

### Compliance Statement
All training, validation, and testing operations reference only their respective directories with no cross-contamination or hard-coded paths. This ensures full compliance with the Duality AI Space Station Challenge dataset usage requirements.

---

### ğŸ“¦ Data Preparation

- **Download the Falcon Dataset:**  
  [Download here](#) <!-- Replace with actual link if available -->

- **Unzip & Place:**  
  Extract the dataset and copy its contents to:

  ```
  data/raw/
  ```

> **Note:** The dataset is NOT included in this repository due to its size. Please download it manually.

---

### ğŸ‹ï¸â€â™‚ï¸ Training

Train the model on your machine:

```bash
python src/train.py
```

---

### ğŸ” Inference

Detect objects in a sample image:

```bash
python src/detect.py data/raw/test/images/sample.jpg
```

---

### ğŸ–¥ï¸ Demo Application

Experience VISTA-S through the interactive web app:

1. **Navigate to the app directory:**

    ```bash
    cd app
    ```

2. **Install requirements:**

    ```bash
    pip install -r requirements.txt
    ```

3. **Start the backend server:**

    ```bash
    python backend.py
    ```

---

## ğŸ“Š Performance

VISTA-S achieves exceptional results on the Falcon dataset:

- **Precision:** ~0.9797
- **Recall:** ~0.9088
- **mAP@0.5:** ~0.9416
- **mAP@0.5:0.95:** ~0.8843

These scores are based on the YOLOv8 architecture.  
For detailed logs and more metrics, see the `models/logs/yolov8_observo/` directory.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                   # Flask backend app
â”‚   â”œâ”€â”€ backend.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ simple_backend.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ config/
â”‚   â””â”€â”€ observo.yaml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ classes.txt
â”‚       â”œâ”€â”€ predict.py
â”‚       â”œâ”€â”€ train.py
â”‚       â”œâ”€â”€ visualize.py
â”‚       â”œâ”€â”€ yolo_params.yaml
â”‚       â””â”€â”€ data/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ report_outline.md
â”œâ”€â”€ mobile/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ screens/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ SETUP.md
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ weights/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb
â”‚   â””â”€â”€ train_yolov8.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detect.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ constraints.txt
â”œâ”€â”€ uploads/
â”œâ”€â”€ Web_App_frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ hooks/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ environment.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements_minimal.txt
â”œâ”€â”€ render.yaml
â”œâ”€â”€ gunicorn_config.py
â”œâ”€â”€ Procfile
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ DEPLOYMENT.md
â””â”€â”€ README.md
```

<p align="center">
  <img src="https://github.com/user-attachments/assets/ef5defcd-19df-4515-be84-acdd09346f24" width="47%" alt="Vista Sample 1">
  <img src="https://github.com/user-attachments/assets/bd32a41b-ecf9-48e3-b233-11f638d9783c" width="47%" alt="Vista Sample 2">
  <br><br>
  <img src="https://github.com/user-attachments/assets/ad7b5e0a-3c0a-47b6-8202-efc10d108cd2" width="47%" alt="Vista Sample 3">
  <img src="https://github.com/user-attachments/assets/1b65551c-454b-4799-b8dc-136a10ea9b26" width="47%" alt="Vista Sample 4">
</p>
---

## âš ï¸ DO NOT COMMIT SENSITIVE OR LARGE FILES

- **Model weights, logs, uploads, and raw data are excluded via `.gitignore`.**
- **Do NOT commit files in `models/weights/`, `models/logs/`, `uploads/`, or `data/raw/`.**
- **Notebooks and environment folders are also excluded.**

---

## ğŸ¤ Contributing

We welcome your contributions!

1. **Fork** the repository.
2. **Create a branch** for your changes.
3. **Submit a pull request** with a clear description.

For major changes or new features, please open an issue first to discuss.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

---

<p align="center">
  âœ¨ Explore the universe with VISTA-S! <br>
  Star the repo, open issues, or contribute to its growth.<br>
  Your feedback and contributions are always welcome.
</p>
