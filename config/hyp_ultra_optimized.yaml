# Ultra-Optimized Hyperparameters for 90%+ mAP50 Performance
# Designed for Duality AI Space Station Challenge

# Learning rate optimization
lr0: 0.001          # Initial learning rate (reduced for fine-tuning)
lrf: 0.01           # Final learning rate (lr0 * lrf)
momentum: 0.937     # SGD momentum/Adam beta1
weight_decay: 0.0005 # Optimizer weight decay
warmup_epochs: 5.0  # Warmup epochs (fractions ok)
warmup_momentum: 0.8 # Warmup initial momentum
warmup_bias_lr: 0.1 # Warmup initial bias lr

# Loss function weights (optimized for detection)
box: 7.5            # Box loss gain (increased for better localization)
cls: 0.5            # Class loss gain (balanced)
dfl: 1.5            # Distribution focal loss gain

# Data augmentation (aggressive for better generalization)
hsv_h: 0.015        # Image HSV-Hue augmentation (fraction)
hsv_s: 0.7          # Image HSV-Saturation augmentation (fraction)
hsv_v: 0.4          # Image HSV-Value augmentation (fraction)
degrees: 10.0       # Image rotation (+/- deg)
translate: 0.2      # Image translation (+/- fraction)
scale: 0.9          # Image scale (+/- gain)
shear: 2.0          # Image shear (+/- deg)
perspective: 0.0001 # Image perspective (+/- fraction), range 0-0.001
flipud: 0.5         # Image flip up-down (probability)
fliplr: 0.5         # Image flip left-right (probability)
mosaic: 1.0         # Image mosaic (probability)
mixup: 0.15         # Image mixup (probability)
copy_paste: 0.3     # Segment copy-paste (probability)

# Advanced optimizations
anchor_t: 4.0       # Anchor-multiple threshold
anchors: 3          # Anchors per output layer (0 to ignore)
fl_gamma: 0.0       # Focal loss gamma (efficientDet default gamma=1.5)
label_smoothing: 0.1 # Label smoothing epsilon
nbs: 64             # Nominal batch size
dropout: 0.0        # Use dropout regularization (classify train only)

# Multi-scale and advanced training
multi_scale: true   # Enable multi-scale training
rect: false         # Rectangular training (disabled for better augmentation)
cache: true         # Cache images for faster training
device: ''          # Auto-select device
optimizer: 'AdamW'  # Use AdamW optimizer (better than SGD for detection)
close_mosaic: 10    # Disable mosaic augmentation in last N epochs

# Training control
patience: 100       # Early stopping patience (epochs)
save_period: 10     # Save checkpoint every N epochs
val: true           # Validate during training
plots: true         # Generate training plots
exist_ok: true      # Overwrite existing project
pretrained: true    # Use pretrained weights
verbose: true       # Verbose output
seed: 42            # Random seed for reproducibility
deterministic: true # Deterministic training
single_cls: false   # Multi-class detection
image_weights: false # Don't use image weights (can cause overfitting)
cos_lr: true        # Use cosine learning rate scheduler
auto_augment: 'randaugment' # Advanced auto-augmentation
erasing: 0.4        # Random erasing probability
crop_fraction: 1.0  # Crop fraction for training